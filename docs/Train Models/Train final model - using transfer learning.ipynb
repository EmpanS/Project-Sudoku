{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "In this jupyter notebook, we will train the final model using transfer learning. The idea of transfer learning is to take\n",
    "knowledge gained from solving one problem and apply this knowledge on a similar, but different, problem. We can transfer the knowledge gathered from the MNIST-dataset and apply it to our dataset. In this case, we can take our model trained on the MNIST-dataset, freeze all parameters, change the output layer and then train the model on our the new dataset. By freezing the parameters from the old model we can ensure that only the last classification layer gets trained. A nice additional benefit from this is that it will also reduce the training time significantly because we are only training the variables of our last classification layer and not the entire model.\n",
    "\n",
    "I have personally created the new dataset. I found an old Sudoku-book and took pictures of 56 unsolved Sudokus. Then, I used the data pipeline to process all 56 images resulting in 56 x 81 images. Once processed, I saved all images containing a number, summing up to a total of 1282 images. Next, I labeled the data using a Python script that quickly showed each picture and registered inputs from my keyboard. This resulted in 1282 labeled pictures which we now can use to train our final model. The training images are found in \\training images and are named on the format: Label__index.jpg\n",
    "\n",
    "We start by installing useful dependencies and importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install useful dependencies\n",
    "!pip3 install --upgrade numpy==1.16.4\n",
    "!pip3 install --upgrade keras\n",
    "!pip3 install --upgrade tensorflow\n",
    "!pip3 install --upgrade matplotlib\n",
    "!pip3 install --upgrade opencv-python\n",
    "!pip3 install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import os.path as path\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 9\n",
    "EPOCHS = 50\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to extract the images from the zip file to a new folder Training images.\n",
    "archive = zipfile.ZipFile('Training images - final model.zip')\n",
    "for file in archive.namelist():\n",
    "    archive.extract(file, os.getcwd() + '\\Training images - final model')\n",
    "\n",
    "\n",
    "BASE_PATH = os.getcwd() + \"\\Training images - final model\\\\\"\n",
    "NUM_EXAMPLES = len(os.listdir(BASE_PATH))\n",
    "DIM = 28\n",
    "\n",
    "# Load training and test data\n",
    "X = np.zeros((NUM_EXAMPLES, DIM, DIM, 1))\n",
    "y = np.zeros((NUM_EXAMPLES,))\n",
    "for idx, image_path in enumerate(os.listdir(BASE_PATH)):\n",
    "    image = cv2.imread(BASE_PATH + image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Normalize and reshape image\n",
    "    image = image / 255\n",
    "    image = np.reshape(image, (DIM,DIM,1))\n",
    "    # label 0 represents number 1, ..., label 8 represents number 9\n",
    "    label = int(image_path.split(\"__\")[0]) - 1\n",
    "    X[idx] = image\n",
    "    y[idx] = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the model trained on the MNIST-dataset. Then we freeze all parameters and remove the last layer. Then we add a new last layer with 9 neurons since we want to be able to predict the numbers 1-9. The first model is trained on 10 digits (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Emil\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Emil\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Emil\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model = load_model(\"Trained model\")\n",
    "\n",
    "# Remove last layer, set layers to un-trainable and add new output layer\n",
    "model.pop()\n",
    "for l in model.layers:\n",
    "    l.trainable = False\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax', name=\"Output\"))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 858 samples, validate on 424 samples\n",
      "Epoch 1/50\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 3.3656 - acc: 0.1970 - val_loss: 1.2871 - val_acc: 0.6014\n",
      "Epoch 2/50\n",
      "858/858 [==============================] - 0s 223us/step - loss: 1.7917 - acc: 0.4499 - val_loss: 0.4338 - val_acc: 0.9505\n",
      "Epoch 3/50\n",
      "858/858 [==============================] - 0s 228us/step - loss: 0.9772 - acc: 0.6830 - val_loss: 0.1901 - val_acc: 0.9976\n",
      "Epoch 4/50\n",
      "858/858 [==============================] - 0s 372us/step - loss: 0.6159 - acc: 0.7972 - val_loss: 0.1037 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "858/858 [==============================] - 0s 442us/step - loss: 0.4556 - acc: 0.8392 - val_loss: 0.0635 - val_acc: 0.9976\n",
      "Epoch 6/50\n",
      "858/858 [==============================] - 0s 248us/step - loss: 0.3190 - acc: 0.9056 - val_loss: 0.0447 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "858/858 [==============================] - 0s 428us/step - loss: 0.2443 - acc: 0.9324 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "858/858 [==============================] - 0s 434us/step - loss: 0.1937 - acc: 0.9429 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "858/858 [==============================] - 0s 374us/step - loss: 0.1379 - acc: 0.9662 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "858/858 [==============================] - 0s 424us/step - loss: 0.1206 - acc: 0.9720 - val_loss: 0.0150 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "858/858 [==============================] - 0s 430us/step - loss: 0.1115 - acc: 0.9720 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "858/858 [==============================] - 0s 420us/step - loss: 0.0772 - acc: 0.9860 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "858/858 [==============================] - 0s 445us/step - loss: 0.0736 - acc: 0.9883 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "858/858 [==============================] - 0s 417us/step - loss: 0.0572 - acc: 0.9895 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "858/858 [==============================] - 0s 419us/step - loss: 0.0595 - acc: 0.9883 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "858/858 [==============================] - 0s 458us/step - loss: 0.0432 - acc: 0.9953 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "858/858 [==============================] - 0s 448us/step - loss: 0.0462 - acc: 0.9907 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "858/858 [==============================] - 0s 452us/step - loss: 0.0366 - acc: 0.9953 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "858/858 [==============================] - 0s 456us/step - loss: 0.0385 - acc: 0.9930 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "858/858 [==============================] - 0s 508us/step - loss: 0.0343 - acc: 0.9942 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "858/858 [==============================] - 0s 475us/step - loss: 0.0283 - acc: 0.9977 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "858/858 [==============================] - 0s 364us/step - loss: 0.0251 - acc: 0.9977 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "858/858 [==============================] - 0s 458us/step - loss: 0.0314 - acc: 0.9942 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "858/858 [==============================] - 0s 446us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "858/858 [==============================] - 0s 456us/step - loss: 0.0249 - acc: 0.9942 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "858/858 [==============================] - 0s 479us/step - loss: 0.0188 - acc: 0.9977 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "858/858 [==============================] - 0s 421us/step - loss: 0.0159 - acc: 0.9988 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "858/858 [==============================] - 0s 425us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "858/858 [==============================] - 0s 450us/step - loss: 0.0179 - acc: 0.9988 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "858/858 [==============================] - 0s 420us/step - loss: 0.0130 - acc: 0.9988 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "858/858 [==============================] - 0s 424us/step - loss: 0.0096 - acc: 0.9988 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "858/858 [==============================] - 0s 448us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "858/858 [==============================] - 0s 415us/step - loss: 0.0125 - acc: 0.9988 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "858/858 [==============================] - 0s 433us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "858/858 [==============================] - 0s 428us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "858/858 [==============================] - 0s 413us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 9.6836e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "858/858 [==============================] - 0s 446us/step - loss: 0.0154 - acc: 0.9953 - val_loss: 9.1776e-04 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "858/858 [==============================] - 0s 410us/step - loss: 0.0126 - acc: 0.9977 - val_loss: 8.7144e-04 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "858/858 [==============================] - 0s 405us/step - loss: 0.0121 - acc: 0.9988 - val_loss: 7.5066e-04 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "858/858 [==============================] - 0s 417us/step - loss: 0.0082 - acc: 0.9988 - val_loss: 7.8527e-04 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "858/858 [==============================] - 0s 409us/step - loss: 0.0078 - acc: 0.9977 - val_loss: 7.7103e-04 - val_acc: 1.0000\n",
      "Epoch 00041: early stopping\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (41,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5ca0b2e43a8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower right'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2793\u001b[0m     return gca().plot(\n\u001b[0;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2795\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m         \"\"\"\n\u001b[0;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1666\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1667\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 270\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (41,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model\n",
    "earlystopper = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "session = model.fit(X_train, y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[earlystopper])\n",
    "\n",
    "acc = session.history['acc']\n",
    "val_acc = session.history['val_acc']\n",
    "\n",
    "loss = session.history['loss']\n",
    "val_loss = session.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the earlystopper did not kick in, the validation loss decreased continously throughout the training session, but we have a validation accuracy of 100%. At first sight, this might seem strange, but remember, we are training on computer genererated numbers, so the numbers are very similar and the model will be used to predict computer generated numbers.\n",
    "\n",
    "Now we have our final model, ready to be used in the project to predict numbers! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path.abspath(path.join(os.getcwd(),\"../..\")) + \"/project\" + \"\\Final model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
